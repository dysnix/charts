image:
  repository: ethereum/client-go
  pullPolicy: IfNotPresent
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

updateStrategy:
  type: RollingUpdate

## Geth v1.13+ with --state.scheme=path shuts down way faster.
terminationGracePeriodSeconds: 300

## Extra pod labels
podLabels: {}
  # environment: production

## This labels mark Geth node as ready to serve the traffic.
## Used as selector for RPC service together with `.Values.podLabels` and default labels.
podStatusLabels: {}
  # manualstatus: in-service

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000
  # runAsGroup: 1000

## Override geth container command (can be templated)
command: []

## Extra container arguments (can be templated)
extraArgs: []

## Extra init containers, can be templated
initContainers: []
  # - name: dumpconfig
  #   image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
  #   imagePullPolicy: "{{ .Values.image.pullPolicy }}"
  #   command: ["--config", "/config/config.toml", "dumpconfig"]
  #   volumeMounts:
  #   - name: config
  #     mountPath: /config

## Sidecar containers, can be templated
sidecarContainers: []
  # - name: exporter
  #   image: ethpandaops/ethereum-metrics-exporter:latest
  #   imagePullPolicy: Always
  #   args:
  #   - --execution-url=http://localhost:{{ .Values.config.node.http.port }}
  #   ports:
  #   - name: exporter
  #     containerPort: 9090

## Services config
services:
  p2p:
    enabled: true
    type: NodePort
    loadBalancerIP: ""
    port: 30303
    # it's better to set nodePort equal to .Values.config.node.p2p.port when the svc type is "NodePort"
    # nodePort: 30303
  p2pDiscovery:
    enabled: true
    type: NodePort
    loadBalancerIP: ""
    port: 30301
    # it's better to set nodePort equal to .Values.config.node.p2p.port when the svc type is "NodePort"
    # nodePort: 30301
  rpc:
    enabled: true
    type: ClusterIP
    httpPort: 8545
    wsPort: 8546
  metrics:
    enabled: false
    type: ClusterIP
    port: 6060
  authrpc:
    enabled: true
    type: ClusterIP
    port: 8551

ingress:
  http:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      # cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts: []
      # - host: geth.local
      #   paths:
      #     - path: /
      #       pathType: ImplementationSpecific
    tls: []
      # - secretName: geth-tls
      #   hosts:
      #     - geth.local
  ws:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      # cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      # - host: geth-ws.local
      #   paths:
      #     - path: /
      #       pathType: ImplementationSpecific
    tls: []
      # - secretName: geth-ws-tls
      #   hosts:
      #     - geth-ws.local

persistence:
  type: pvc
  # type: hostPath
  pvc:
    size: 900Gi                # starting point for snap-synced node as of 2023-09
    accessMode: ReadWriteOnce
    storageClass: ""           # set to "-" if you want to manually create persistent volume
    annotations: {}
  hostPath:
    path: /data/geth
    type: Directory            # by default you need to create directory yourself

affinity: {}

nodeSelector: {}

tolerations: []

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# Create Prometheus Operator serviceMonitor
serviceMonitor:
  enabled: false
  # interval: 10s
  # scrapeTimeout: 2s
  # honorLabels: true
  # relabelings: []
  # metricRelabelings: []

# Assume that node is stuck if it's lag is more than 300 seconds.
# .livenessProbe.exec.command can also be in a templated string format
livenessProbe:
  enabled: false
  initialDelaySeconds: 120
  periodSeconds: 60
  successThreshold: 1
  failureThreshold: 3
  timeoutSeconds: 10
  exec:
    command:
      - sh
      - /scripts/check-readiness.sh
      - "300"

# Assume that node is not ready to serve traffic if it's lag is more than 60 seconds.
# .readinessProbe.exec.command can also be in a templated string format
readinessProbe:
  enabled: false
  initialDelaySeconds: 60
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 1
  timeoutSeconds: 5
  exec:
    command:
      - sh
      - /scripts/check-readiness.sh
      - "60"

## Main Geth config
config:
  ## Use a utility like OpenSSL to create JWT via command: openssl rand -hex 32
  jwt: ""
  eth:
    network: mainnet
    syncMode: snap
    gcMode: full
    txLookupLimit: 2350000
    transactionHistory: 2350000
    stateHistory: 90000
    stateScheme: hash
    preimages: false
  node:
    ipc:
      enabled: true
      path: geth.ipc
    http:
      enabled: true
      port: 8545
      vhosts: ["*"]
      cors: ["*"]
      modules: ["eth", "net", "web3"]
    authrpc:
      port: 8551
      vhosts: ["*"]
    ws:
      enabled: false
      port: 8546
      origins: ["*"]
      modules: ["eth", "net", "web3"]
    p2p:
      useHostPort: false    # if set to true .Values.services.p2p will be disabled, and hostPort will be allocated instead
      port: 30303
      discoveryPort: 30301
      nat: ""               # you may want to set it if you are running P2P via NodePort/LoadBalancer k8s svc
      maxPeers: 50
      noDiscovery: false
      bootstrapNodes: []
      bootstrapNodesV5: []
      staticNodes: []
      trustedNodes: []
  cache: 4096
  verbosity: 3
  vmodule: []
  # - rpc=5
  metrics:
    enabled: false
    expensive: false
    port: 6060
